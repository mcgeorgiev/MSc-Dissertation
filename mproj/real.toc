\contentsline {chapter}{\numberline {1}Introduction}{5}
\contentsline {section}{\numberline {1.1}Motivation}{5}
\contentsline {section}{\numberline {1.2}Objective}{6}
\contentsline {section}{\numberline {1.3}System Overview}{6}
\contentsline {section}{\numberline {1.4}Outline}{6}
\contentsline {chapter}{\numberline {2}Background Survey}{8}
\contentsline {section}{\numberline {2.1}Mobile Robots}{8}
\contentsline {subsection}{\numberline {2.1.1}Turtlebot 2}{8}
\contentsline {subsection}{\numberline {2.1.2}Cameras}{9}
\contentsline {section}{\numberline {2.2}Robot Operating System (ROS)}{10}
\contentsline {subsection}{\numberline {2.2.1}How does ROS work?}{10}
\contentsline {section}{\numberline {2.3}SLAM (Simultaneous Localisation and Mapping)}{11}
\contentsline {subsection}{\numberline {2.3.1}RTABMap}{13}
\contentsline {section}{\numberline {2.4}Object Detection and Classification}{14}
\contentsline {subsection}{\numberline {2.4.1}Introduction}{14}
\contentsline {subsection}{\numberline {2.4.2}Detection in the Natural World}{15}
\contentsline {subsection}{\numberline {2.4.3}Extracting Features}{15}
\contentsline {subsubsection}{FAST Feature Detection}{15}
\contentsline {subsection}{\numberline {2.4.4}Object Classification with Deep Learning}{16}
\contentsline {subsubsection}{Convolutional Neural Networks (CNN)}{16}
\contentsline {subsubsection}{MobileNet with TensorFlow}{18}
\contentsline {subsubsection}{Google Vision API}{18}
\contentsline {subsection}{\numberline {2.4.5}Regions with Convolutional Neural Networks (R-CNN)}{18}
\contentsline {section}{\numberline {2.5}Conclusion}{19}
\contentsline {chapter}{\numberline {3}System Design}{20}
\contentsline {section}{\numberline {3.1}Requirements}{20}
\contentsline {subsection}{\numberline {3.1.1}Functional Requirements}{21}
\contentsline {subsection}{\numberline {3.1.2}Functional Requirements}{21}
\contentsline {subsection}{\numberline {3.1.3}MOSCOW TABLE}{22}
\contentsline {section}{\numberline {3.2}Design Approach}{22}
\contentsline {subsection}{\numberline {3.2.1}Alternative Approaches}{22}
\contentsline {section}{\numberline {3.3}System Architecture}{23}
\contentsline {section}{\numberline {3.4}Conclusion}{24}
\contentsline {chapter}{\numberline {4}Implementation}{25}
\contentsline {section}{\numberline {4.1}Mapping}{25}
\contentsline {section}{\numberline {4.2}Frontier Exploration}{25}
\contentsline {section}{\numberline {4.3}Object Detection and Recognition}{26}
\contentsline {subsection}{\numberline {4.3.1}Detection}{27}
\contentsline {subsubsection}{0. Initial Exploratory Blob Detection}{27}
\contentsline {subsubsection}{1. Thresholding with Otsu's Method}{27}
\contentsline {subsubsection}{1.5. Calibration Tool}{28}
\contentsline {subsubsection}{2. Combining with a Depth Mask}{28}
\contentsline {subsubsection}{3. Clustering}{28}
\contentsline {subsubsection}{4. Creating Bounding Boxes}{30}
\contentsline {subsection}{\numberline {4.3.2}Classification}{31}
\contentsline {subsubsection}{Haar Cascade}{31}
\contentsline {subsubsection}{Robot Visual Memory Model}{31}
\contentsline {subsubsection}{Implementing the Memory Model}{32}
\contentsline {subsubsection}{Adding Object Persistance}{32}
\contentsline {section}{\numberline {4.4}Conclusion}{33}
\contentsline {chapter}{\numberline {5}Evaluation}{35}
\contentsline {section}{\numberline {5.1}Testing}{35}
\contentsline {subsection}{\numberline {5.1.1}Experiments}{35}
\contentsline {subsubsection}{Experiment Setup}{36}
\contentsline {subsubsection}{Experiment 1}{36}
\contentsline {subsubsection}{Experiment 2}{37}
\contentsline {subsubsection}{Experiment 3}{38}
\contentsline {section}{\numberline {5.2}Conclusion}{40}
\contentsline {chapter}{\numberline {6}Conclusion}{41}
\contentsline {subsection}{\numberline {6.0.1}Future work}{41}
\contentsline {subsection}{\numberline {6.0.2}Reflection}{41}
\contentsline {chapter}{\numberline {A}Appendix}{42}
\contentsline {section}{\numberline {A.1}User Manual}{42}
